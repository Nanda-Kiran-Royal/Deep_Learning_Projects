{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7936fb02-de92-4116-ae34-3fdbb7a5dbbf",
   "metadata": {},
   "source": [
    "## 1.1 Setting up the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e016a089-c823-4110-9650-8efd40623ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import uuid #---> Used for getting specific uniform identifier\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef5a5a0-48f2-441d-99d3-1810bf9260a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join('data','images')\n",
    "number_images= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862a404c-7a41-4880-b09b-d0844f26cfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting image 0\n",
      "collecting image 1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for imagnum in range(number_images):\n",
    "    print('collecting image {}'.format(imagnum))\n",
    "    ret,frame = cap.read()\n",
    "    imgname = os.path.join(images_path,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname,frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q')    :\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec0e3a56-2afb-48d4-a8e5-295f8da93045",
   "metadata": {},
   "source": [
    "## !.2 Annotate Images with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397d889d-7b8e-4c0d-961d-8c6160b9991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-23 23:00:11.558 python[17989:8647915] +[CATransaction synchronize] called within transaction\n",
      "2023-06-23 23:01:03.618 python[17989:8647915] +[CATransaction synchronize] called within transaction\n",
      "2023-06-23 23:15:13.571 python[17989:8647915] +[CATransaction synchronize] called within transaction\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!labelme\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9dea3ef-74c7-41ff-85fa-bae3bdab7012",
   "metadata": {},
   "source": [
    "# 2. Review Dataset and Build Image Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b403e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c108086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For avoiding OOM errors by setting GPU Memory Consumption Growt\n",
    "pus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus :\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5cdec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/q8/dv8fwkl52qx_2yh5w017lk340000gn/T/ipykernel_17940/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c924f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: /User//nanda//Documents//Deep_learning_Projects//Project2//data//images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mlist_files(\u001b[39m'\u001b[39;49m\u001b[39m/User//nanda//Documents//Deep_learning_Projects//Project2//data//images\u001b[39;49m\u001b[39m'\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensor/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:1303\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1296\u001b[0m condition \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mgreater(array_ops\u001b[39m.\u001b[39mshape(matching_files)[\u001b[39m0\u001b[39m], \u001b[39m0\u001b[39m,\n\u001b[1;32m   1297\u001b[0m                              name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmatch_not_empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1299\u001b[0m message \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39madd(\n\u001b[1;32m   1300\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNo files matched pattern: \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1301\u001b[0m     string_ops\u001b[39m.\u001b[39mreduce_join(file_pattern, separator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m assert_not_empty \u001b[39m=\u001b[39m control_flow_assert\u001b[39m.\u001b[39;49mAssert(\n\u001b[1;32m   1304\u001b[0m     condition, [message], summarize\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39massert_not_empty\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1305\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies([assert_not_empty]):\n\u001b[1;32m   1306\u001b[0m   matching_files \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39midentity(matching_files)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensor/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensor/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_assert.py:102\u001b[0m, in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    100\u001b[0m     xs \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_n_to_tensor(data)\n\u001b[1;32m    101\u001b[0m     data_str \u001b[39m=\u001b[39m [_summarize_eager(x, summarize) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xs]\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError(\n\u001b[1;32m    103\u001b[0m         node_def\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    104\u001b[0m         op\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    105\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to be true. Summarized data: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    106\u001b[0m         (condition, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(data_str)))\n\u001b[1;32m    107\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mAssert\u001b[39m\u001b[39m\"\u001b[39m, [condition, data]) \u001b[39mas\u001b[39;00m name:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: /User//nanda//Documents//Deep_learning_Projects//Project2//data//images'"
     ]
    }
   ],
   "source": [
    "images = tf.data.Dataset.list_files('/User//nanda//Documents//Deep_learning_Projects//Project2//data//images',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
